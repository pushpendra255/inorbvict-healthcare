import streamlit as st
import os
import requests
from PyPDF2 import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --------------------------
# ğŸ”‘ Groq API Config
# --------------------------
groq_api_key = "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"
groq_url = "https://api.groq.com/openai/v1/chat/completions"
headers = {
    "Authorization": f"Bearer {groq_api_key}",
    "Content-Type": "application/json"
}

# --------------------------
# PART A - Flow Based Chatbot
# --------------------------
def flow_based_chat():
    st.subheader("ğŸ—£ï¸ Flow-Based Chatbot (Part A)")
    st.caption("Fill in your details step by step, and get a professional profile summary.")

    if "step" not in st.session_state:
        st.session_state.step = 1
    if "responses" not in st.session_state:
        st.session_state.responses = {}

    if st.session_state.step == 1:
        name = st.text_input("ğŸ‘‰ Full Name")
        if st.button("Next â¡ï¸"):
            if name.strip():
                st.session_state.responses["Name"] = name
                st.session_state.step = 2
                st.rerun()
            else:
                st.warning("Please enter your name.")

    elif st.session_state.step == 2:
        age = st.number_input("ğŸ‚ Age", min_value=10, max_value=100, step=1)
        if st.button("Next â¡ï¸"):
            st.session_state.responses["Age"] = age
            st.session_state.step = 3
            st.rerun()

    elif st.session_state.step == 3:
        email = st.text_input("ğŸ“§ Email Address")
        if st.button("Next â¡ï¸"):
            if "@" in email and "." in email:
                st.session_state.responses["Email"] = email
                st.session_state.step = 4
                st.rerun()
            else:
                st.warning("Enter a valid email.")

    elif st.session_state.step == 4:
        skills = st.text_area("ğŸ’¡ Key Skills (comma separated)")
        if st.button("Next â¡ï¸"):
            st.session_state.responses["Skills"] = skills
            st.session_state.step = 5
            st.rerun()

    elif st.session_state.step == 5:
        exp = st.radio("ğŸ“Œ Experience", ["Fresher", "1-2 years", "3-5 years", "5+ years"])
        if st.button("Finish âœ…"):
            st.session_state.responses["Experience"] = exp
            st.session_state.step = 6
            st.rerun()

    elif st.session_state.step == 6:
        st.success("âœ… Profile Completed")
        st.markdown(f"""
        ### ğŸ‰ Candidate Profile
        - **ğŸ‘¤ Name:** {st.session_state.responses.get("Name")}
        - **ğŸ‚ Age:** {st.session_state.responses.get("Age")}
        - **ğŸ“§ Email:** {st.session_state.responses.get("Email")}
        - **ğŸ’¡ Skills:** {st.session_state.responses.get("Skills")}
        - **ğŸ“Œ Experience:** {st.session_state.responses.get("Experience")}
        """)
        st.balloons()
        if st.button("ğŸ”„ Restart Form"):
            st.session_state.step = 1
            st.session_state.responses = {}
            st.rerun()

# --------------------------
# PART B - RAG Chatbot (PDFs + Groq API)
# --------------------------
def extract_text_from_pdfs(uploaded_files):
    all_texts = []
    for uploaded_file in uploaded_files:
        pdf_reader = PdfReader(uploaded_file)
        text = ""
        for page in pdf_reader.pages:
            try:
                text += page.extract_text() + " "
            except:
                continue
        all_texts.append(text.strip())
    return all_texts

def build_vectorstore(texts):
    vectorizer = TfidfVectorizer(stop_words="english")
    embeddings = vectorizer.fit_transform(texts)
    return vectorizer, embeddings

def query_groq(user_query, context=""):
    """Send query to Groq API with optional context"""
    try:
        payload = {
            "model": "llama-3.1-8b-instant",
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": f"Context: {context}\n\nQuestion: {user_query}"}
            ],
            "temperature": 0.7
        }
        response = requests.post(groq_url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"âš ï¸ Error contacting Groq API: {e}"

def rag_chatbot():
    st.subheader("ğŸ“š RAG Chatbot (Part B)")
    st.caption("Upload documents and ask focused questions. Answers come from your PDFs, fallback to Groq API.")

    if "vectorizer" not in st.session_state:
        st.session_state.vectorizer = None
        st.session_state.embeddings = None
        st.session_state.docs = None

    uploaded_files = st.file_uploader("ğŸ“‚ Upload up to 20 PDFs", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if len(uploaded_files) > 20:
            st.error("âš ï¸ You can upload maximum 20 PDFs.")
            return
        texts = extract_text_from_pdfs(uploaded_files)
        vectorizer, embeddings = build_vectorstore(texts)
        st.session_state.vectorizer = vectorizer
        st.session_state.embeddings = embeddings
        st.session_state.docs = texts
        st.success("âœ… Documents processed. You may now ask a question.")

    query = st.text_input("ğŸ’­ Your Question")
    if st.button("Submit Question"):
        if query and st.session_state.vectorizer is not None:
            q_vec = st.session_state.vectorizer.transform([query])
            sims = cosine_similarity(q_vec, st.session_state.embeddings).flatten()
            idx = sims.argmax()

            if sims[idx] > 0.2:  # relevant answer
                context = st.session_state.docs[idx][:1000]
                answer = query_groq(query, context)
                st.markdown("### ğŸ“ Answer from Documents")
                st.info(answer)
            else:
                st.markdown("### ğŸŒ No match in documents, fallback to Groq API")
                answer = query_groq(query)
                st.info(answer)

        elif query and st.session_state.vectorizer is None:
            st.markdown("### ğŸŒ No documents uploaded, answering via Groq API")
            answer = query_groq(query)
            st.info(answer)

# --------------------------
# PART C - Free Chat Interface
# --------------------------
def free_chat():
    st.subheader("ğŸ’¬ Free Chatbot (Part C)")
    st.caption("Chat casually with the bot. It remembers your conversation like a real chat.")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ğŸ“Œ Show all previous messages above input box
    for role, msg in st.session_state.chat_history:
        if role == "user":
            st.markdown(
                f"<div style='text-align:right;padding:10px;margin:5px 0;color:white;background:#0B93F6;border-radius:10px;max-width:70%;margin-left:auto;'><b>You:</b> {msg}</div>",
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f"<div style='text-align:left;padding:10px;margin:5px 0;background:#E5E5EA;border-radius:10px;max-width:70%;margin-right:auto;'><b>Bot:</b> {msg}</div>",
                unsafe_allow_html=True
            )

    # ğŸ“ Chat input (auto clears & submit on Enter)
    user_input = st.chat_input("Type your message...")

    if user_input:  
        # Add user message
        st.session_state.chat_history.append(("user", user_input))

        # Call Groq API for reply
        bot_reply = query_groq(user_input)
        st.session_state.chat_history.append(("bot", bot_reply))

        st.rerun()  # ğŸ”„ rerun to refresh UI & clear input

if __name__ == "__main__":
    main()
